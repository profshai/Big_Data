{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "clustering_seeds.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profshai/pyspark-big-data/blob/main/clustering_seeds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am5Dm78LJRjb"
      },
      "source": [
        "# Group observations into 3 groups using K-Means Clustering\n",
        "\n",
        "Dataset comes from UCI repository: https://archive.ics.uci.edu/ml/datasets/seeds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9o8YTLVJRjc"
      },
      "source": [
        "There are three different varieties of wheat: Kama, Rosa and Canadian, 70 elements each, randomly selected for \n",
        "the experiment.\n",
        "\n",
        "Seven geometric parameters of wheat kernels were measured: \n",
        "1. area A, \n",
        "2. perimeter P, \n",
        "3. compactness C = 4*pi*A/P^2, \n",
        "4. length of kernel, \n",
        "5. width of kernel, \n",
        "6. asymmetry coefficient \n",
        "7. length of kernel groove. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUuhxzjIJmpA",
        "outputId": "0a190f8a-17d5-4a2b-e5c2-895410003107"
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4MB 74kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 15.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=ec25384ab9c5936e8d1d6d0ee5f260c9527204501e5295864fd0f48f1ad74c1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8a8N2Rc3JRjc"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('cluster').getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJcZV2U8JRjc"
      },
      "source": [
        "# Load data.\n",
        "dataset = spark.read.csv(\"seeds_dataset.csv\",header=True,inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A__VhoEzJRjc",
        "outputId": "ae1071e5-52e1-468f-b918-21ae020488de"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(area=15.26, perimeter=14.84, compactness=0.871, length_of_kernel=5.763, width_of_kernel=3.312, asymmetry_coefficient=2.221, length_of_groove=5.22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quEo44OAJRjd",
        "outputId": "b46a7a01-9ec2-4745-f654-fca633b292d3"
      },
      "source": [
        "dataset.describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+------------------+--------------------+-------------------+------------------+---------------------+-------------------+\n",
            "|summary|              area|         perimeter|         compactness|   length_of_kernel|   width_of_kernel|asymmetry_coefficient|   length_of_groove|\n",
            "+-------+------------------+------------------+--------------------+-------------------+------------------+---------------------+-------------------+\n",
            "|  count|               210|               210|                 210|                210|               210|                  210|                210|\n",
            "|   mean|14.847523809523816|14.559285714285718|  0.8709985714285714|  5.628533333333335| 3.258604761904762|   3.7001999999999997|  5.408071428571429|\n",
            "| stddev|2.9096994306873647|1.3059587265640225|0.023629416583846364|0.44306347772644983|0.3777144449065867|   1.5035589702547392|0.49148049910240543|\n",
            "|    min|             10.59|             12.41|              0.8081|              4.899|              2.63|                0.765|              4.519|\n",
            "|    max|             21.18|             17.25|              0.9183|              6.675|             4.033|                8.456|               6.55|\n",
            "+-------+------------------+------------------+--------------------+-------------------+------------------+---------------------+-------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAPVhXWBJRjd"
      },
      "source": [
        "## Format the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "4g8Uu4TMJRje"
      },
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5jwL5_WJRjf",
        "outputId": "98410b78-fad8-4af7-a335-93be75ab6165"
      },
      "source": [
        "dataset.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['area',\n",
              " 'perimeter',\n",
              " 'compactness',\n",
              " 'length_of_kernel',\n",
              " 'width_of_kernel',\n",
              " 'asymmetry_coefficient',\n",
              " 'length_of_groove']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ypBWNZIWJRjf"
      },
      "source": [
        "vec_assembler = VectorAssembler(inputCols = dataset.columns, outputCol='features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "49qHI_2-JRjg"
      },
      "source": [
        "final_data = vec_assembler.transform(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XEOOJT_JRjg"
      },
      "source": [
        "### Scale the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "01hCFRkyJRjg"
      },
      "source": [
        "from pyspark.ml.feature import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSPWrneTJRjg"
      },
      "source": [
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "W1EnnBVuJRjh"
      },
      "source": [
        "# Compute summary statistics by fitting the StandardScaler\n",
        "scalerModel = scaler.fit(final_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx6MSJ9nJRjh"
      },
      "source": [
        "# Normalize each feature to have unit standard deviation.\n",
        "final_data = scalerModel.transform(final_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mitTjIu2MF_c",
        "outputId": "f34b47d8-7b4b-4648-b59e-8f39cf456508"
      },
      "source": [
        "final_data.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(area=15.26, perimeter=14.84, compactness=0.871, length_of_kernel=5.763, width_of_kernel=3.312, asymmetry_coefficient=2.221, length_of_groove=5.22, features=DenseVector([15.26, 14.84, 0.871, 5.763, 3.312, 2.221, 5.22]), scaledFeatures=DenseVector([5.2445, 11.3633, 36.8608, 13.0072, 8.7685, 1.4772, 10.621]))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vakZH_IAJRjh"
      },
      "source": [
        "## Train the Model and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "wkyN_WDBJRjh"
      },
      "source": [
        "# Train k-means model\n",
        "from pyspark.ml.clustering import KMeans\n",
        "kmeans = KMeans(featuresCol='scaledFeatures',k=3)\n",
        "model = kmeans.fit(final_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELLAArCIJRjh",
        "outputId": "d89d7c98-0e72-4e21-c383-02aa6349891c"
      },
      "source": [
        "# Make predictions \n",
        "predictions = model.transform(final_data)\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "\n",
        "# Evaluate clustering by computing Silhouette score\n",
        "evaluator = ClusteringEvaluator()\n",
        "silhouette = evaluator.evaluate(predictions)\n",
        "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Silhouette with squared euclidean distance = 0.6018627534901196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLt3ln6aJRjh",
        "outputId": "2a78cd93-4632-41a4-efa3-4c1fa3f3f38f"
      },
      "source": [
        "# Shows the result.\n",
        "centers = model.clusterCenters()\n",
        "print(\"Cluster Centers: \")\n",
        "for center in centers:\n",
        "    print(center)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster Centers: \n",
            "[ 6.31670546 12.37109759 37.39491396 13.91155062  9.748067    2.39849968\n",
            " 12.2661748 ]\n",
            "[ 4.06105916 10.13979506 35.80536984 11.82133095  7.50395937  3.27184732\n",
            " 10.42126018]\n",
            "[ 4.87257659 10.88120146 37.27692543 12.3410157   8.55443412  1.81649011\n",
            " 10.32998598]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywTr06GaJRjh",
        "outputId": "0005f9f2-0790-4d9e-e640-4c2a1379b5a2"
      },
      "source": [
        "model.transform(final_data).select('prediction').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+\n",
            "|prediction|\n",
            "+----------+\n",
            "|         2|\n",
            "|         2|\n",
            "|         2|\n",
            "|         2|\n",
            "|         2|\n",
            "|         2|\n",
            "|         2|\n",
            "|         2|\n",
            "|         0|\n",
            "|         0|\n",
            "|         2|\n",
            "|         2|\n",
            "|         2|\n",
            "|         2|\n",
            "|         2|\n",
            "|         2|\n",
            "|         2|\n",
            "|         2|\n",
            "|         2|\n",
            "|         1|\n",
            "+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BzcNctsJRjh"
      },
      "source": [
        "End of Notebook!"
      ]
    }
  ]
}